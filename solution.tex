%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages

\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)


\usepackage{graphicx}
\graphicspath{ {./imgs/} }

\usepackage{float}

\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
\normalfont \normalsize 
\textsc{University if Helsinki, Department of Computer Science} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Markov Modeling and Bayesian Learning \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Han Xiao} % Your namea

\date{\normalsize\today} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------

\section{Problem 1}

\lipsum[2] % Dummy text

Sequence generation:

For some given sequence length $T$, the following configuraiton is made:

\begin {itemize}
  \item Each sequence is generated according to some {\em random} state transition probability table $P$.
  \item Each entry in table $P$ is {\em uniformly distribued} (and then normalized).
  \item The starting probabilities for each bigram are equal (0.25).
\end {itemize}


Then {\em 1000} sequences was randomly generated, each of which is used to estimate the parameters by Maximum Likelihood estimation and Bayesian estimation.

Denote the estimated parameters as $P'_{ijk}$ and the true parameters as $P_{ijk}$, the error rate for each estimated paraemter is calculated as:

\[ E_{ijk} = \frac{|P'_{ijk} - P_{ijk}|} {P_{ijk}} \]

And the total error rate of the estimated paramters is calculated as the mean of all the individual error rates:

\[E_{total} = \frac {1} {n} \sum\limits_{ijk} \frac{|P'_{ijk} - P_{ijk}| }{ P_{ijk}}\]

where $n$ is the number of paramters, which is $64$ in this case.

The resuling plot is like: 

\begin{figure}[H]
  \centering
  \includegraphics[scale=.8]{mle-be-estimation}
  \caption{Comparison between MLE and BE for various sequence lengths}
\end{figure}

%how to set matlab plot size
%set(0, 'DefaultFigurePosition', [ left bottom width height ]);



%----------------------------------------------------------------------------------------
%	PROBLEM 4
%----------------------------------------------------------------------------------------

\section{Problem 4}
\subsection {Phenomenon}
I fix $p$ and vary the error parameter $\varepsilon$ from 0 to 1 at a step size of 0.05. Then for each $\varepsilon$, 500 HMM sequences are generated randomly by $P$ and $E$.

The error of the parameter estimation $P^{'}$ is defined as the mean of the element-wise difference between $P$ and $P^{'}$ 

\[ \mathrm{Error} (P^{'}, P) = \frac {1} {4} \sum_{i} \sum_{j} \frac{|P^{'}_{i,j} - P_{i,j}|}{P_{i,j}} \]

The error mean for $p \in \{0.2, 0.5, 0.8\}$ are given below:

\begin{figure}[H]
  \centering
  \includegraphics[scale=.8]{{noisyhmm-errorrate-p=0.200000}.png}
  \caption {ML parameter estimation error when $p$=0.2}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[scale=.8]{{noisyhmm-errorrate-p=0.500000}.png}
  \caption {ML parameter estimation error when $p$=0.5}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[scale=.8]{{noisyhmm-errorrate-p=0.800000}.png}
  \caption {ML parameter estimation error when $p$=0.8}
\end{figure}

\subsection {Explanation}

There are two remarkable oberservations.

\begin{itemize}
\item for $p=0.2$ and $p=0.8$, the error mean first increases. After reaching the peak at about 0.8, it starts to fall.
\item while the plot for $p=0.2$ and $p=0.8$ are very similar, the plot for $p=0.5$ is not the case, it is flat!
\end {itemize}

For the first observation:\newline

Denote the state set as $\{S_1, S_2\}$ and the observation set as $\{O_1, O_2\}$. \newline

For the first observation, it is intuitive to come up that lower error mean results from lower $\varepsilon$. Because the observations reflect the true state transition more or less accurately. 

However, it might be counterintuitive for large $\varepsilon$. Here are some explanation for this counter-intuition. \newline

Let's assume $\varepsilon=1$, in which case each observation is flipped from its true underlying state. That is $S_1$ generates $O_2$ and $S_2$ generates $O_1$. 

We denote the count of certain observations as $C (O_1)$ or $C (O_1, O_2)$ for the count of $(O_1, O_2)$ pairs. Then $C (O_1, O_1) = C (S_2, S_2)$, $C (O_2, O_2) = C (S_1, S_1)$ , $C (O_2, O_1) = C (S_1, S_2)$ and $C (O_1, O_2) = C (S_2, S_1)$ 

As there is only one parameter $p$ for the HMM state transition process, number of sequential pairs $(S_1,S_1) \approx (S_2,S_2)$ should be roughly equal if sample size is large enough. Similarly, $(S_1, S_2) \approx (S_2, S_1)$. 

Also assuming a uniform initial state distribution, $C (S_1) \approx C (S_2)$. \newline

As a result, $C (O_1, O_1)$  should be roughly equal to $C (O_2, O_2)$ and $C (O_2, O_1)$  should be roughly equal to $C (O_1, O_2)$ and $C (O_1)$ is rougly equal to $C (O_2)$. 

\begin {align*}
  P (S_1, S_2) &= \frac {C (S_2)} {C (S_1, S_2)} \\
  &= \frac {C (O_1)} {C (O_2, O_1)} \\
  &\approx \frac {C (O_2)} {C (O_1, O_2)}\\
  &=P (O_1, O_2)
\end {align*}

Therefore, the error mean for large $\varepsilon$ is quite close to that of small $\varepsilon$.

For the second observation:\newline

When $p=0.5$, the state transition process is like tossing a fair coin again and again.

The low error mean for both small and great $p$ can be explained like above. In case $\varepsilon=0.5$, flipping of the observation is like another process of tossing fair coin.

Though certain observations may be flipped, the cases in which $S_1$ emits $O_2$ are compansated by the fact that roughly the same amount of emission from $S_2$ to $O_1$, thus the sufficient statistics does not change much.

As a conclusion, the error mean for $p=0.5$ does not vary much from that of large or small $p$ values.

%------------------------------------------------

\subsection{Example of list (3*itemize)}
\begin{itemize}
	\item First item in a list 
		\begin{itemize}
		\item First item in a list 
			\begin{itemize}
			\item First item in a list 
			\item Second item in a list 
			\end{itemize}
		\item Second item in a list 
		\end{itemize}
	\item Second item in a list 
\end{itemize}

%------------------------------------------------

\subsection{Example of list (enumerate)}
\begin{enumerate}
\item First item in a list 
\item Second item in a list 
\item Third item in a list
\end{enumerate}

%----------------------------------------------------------------------------------------

\end{document}
